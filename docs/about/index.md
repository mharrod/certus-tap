# What is Certus TAP?

Certus TAP is a **research and learning platform** for exploring how to build trustworthy AI systems and better understand how AI can amplify human expertise. It's not a product you deploy. It's a framework you learn from, adapt, and build upon.

The initial focus is on security analysis and assurance, but every architectural component (manifests, guardrails, evidence pipelines, TrustCentre) is domain-agnostic. The same patterns can be applied to other regulated practices—medical research, legal review, compliance audits—by defining new manifest profiles, policies, scanners, and evaluation thresholds.

### What Makes It Different?

- **Evidence-Based Trust**: Cryptographic provenance for every artifact, AI output, and decision
- **Tool-Agnostic**: Built on open standards so you're never locked in
- **Learning-Focused**: Teaches the "Hard Way", no magic buttons, just understanding
- **Research-Driven**: Prioritizes exploration and reproducibility over production readiness
- **Open and Ethical**: Free for research and learning, designed to serve human good
- **Intentional Governance**: Clear decision-making processes protect architectural integrity during early development

### Who we hope this will help?

- **Security Engineers** questioning how to trust AI security tools
- **Researchers** studying AI safety, security, and assurance
- **Builders** implementing AI systems with accountability
- **Learners** wanting to understand AI assurance from first principles
- **Practitioners** needing reproducible, auditable AI workflows
- **Community Organizations** implementing sovereign and ethical AI without dependence on centralized providers
- **Nations & Institutions** seeking to deploy AI infrastructure within their own boundaries while maintaining transparency and accountability

### What Can You Do With It?

- **Experiment** with different AI architectures. For now, the focus is on security analytics but we look to expand to many other areas.
- **Measure** AI effectiveness with reproducible benchmarks
- **Build** provenance and traceability into your AI pipelines
- **Validate** AI outputs with evaluation frameworks
- **Learn** how AI assurance actually works under the hood
- **Research** new approaches to trustworthy AI
